{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "968d8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to have all imports you'll need\n",
    "from scipy.stats import bernoulli, beta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab353da",
   "metadata": {},
   "source": [
    "# Sampling from distribuions\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "Use the `bernoulli` distribution from `scipy.stats` to sample a coin flip, with probability heads equal to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8620d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c7e6c",
   "metadata": {},
   "source": [
    "Write a function that takes in a parameter $p$ denoting the probability of heads, and $n$ the number of coin flips. This function will then generate those $n$ flips and return the result. Test this function by generating $n=1000$ samples with probability $p=0.3$, then plot that result as a histogram. Remember to label your axis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a54156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f637419",
   "metadata": {},
   "source": [
    "Repeat the above 100 different times, but with $p=0.5$. Then add up all the samples and plot the sum as a histogram again. \n",
    "\n",
    "What distribution does this sum of bernoulli samples histogram look like? Explain why *(hint: look up sum of bernoulli trials, and seperately the centeral limit theorem)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4df1dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e193644",
   "metadata": {},
   "source": [
    "# Distributions and link functions\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Use the equation:\n",
    "\n",
    "\n",
    " $$p(y; x, w, g(\\cdot)) = \\frac{g(x, w)^y e ^{-g(x, w)}}{y!}$$\n",
    " \n",
    " To code up the proability mass function of a poisson distribution. \n",
    " \n",
    " Make sure it's output is the same the pmf of the poisson object from `scipy.stats`, that is\n",
    " \n",
    " `poisson_pmf(y, x, w) == poisson.pmf(y, mu=np.exp(x*w))` should evaluate to `True`\n",
    " \n",
    " The `math` library contains the factorial function you'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4126455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import what you need first\n",
    "\n",
    "def poisson_pmf(y, x, w):\n",
    "    pass\n",
    "\n",
    "#below should evaluatte to True, if implemented correctly\n",
    "#np.isclose(poisson_pmf(10, 3, 3), poisson.pmf(10, mu=np.exp(3*3)), atol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5deee01",
   "metadata": {},
   "source": [
    "Repeat the previous exercise but now for a bernoulli distribution\n",
    "\n",
    "$$p(y; x, w, \\sigma(\\cdot)) = \\sigma(xw)^y \\big(1 - \\sigma(xw)\\big)^{1 - y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1be3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bernoulli_pmf(y, x, w):\n",
    "    pass\n",
    "\n",
    "#below should evaluatte to True, if implemented correctly\n",
    "#np.isclose(bernoulli_pmf(1, 8, 0.6), bernoulli.pmf(1, expit(8*0.6)), atol=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133272b4",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "Recall the mouse in the experiment box scenario from the lecture notebook. The mouse has two levers to choose from, one which delivers food, and another which delivers water. \n",
    "\n",
    "We want to know what the mouses preference for water is on a particular day of the week. \n",
    "\n",
    "* What distribution can be used to model the mouses choice in this experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd35ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the appropriate distribution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6eb084",
   "metadata": {},
   "source": [
    "Denote the moues preference for water with the parameter $\\theta$, and say that $P(choice = water) = \\theta$ corresponds to the probability mouse selects water. Additionally, there is data available. We have observed the mouses choices. We'll code $water = 1$, and $food = 0$\n",
    "\n",
    "$d = \\big(0, 1, 1, 0, 1, 1, 0, 1, 0, 1, ... \\big)$\n",
    "\n",
    "We're going to use the data to help us make an inference on what preference for water is\n",
    "\n",
    "If we write out our query of wanting to know the mouses prefrence for water it's: \n",
    "\n",
    "$$P(\\theta | d)$$\n",
    "\n",
    " * now apply Bayes rule (write it in markdown in the cell below):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac8463",
   "metadata": {},
   "source": [
    "$$P(\\theta | d) = your answer here$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75231f6e",
   "metadata": {},
   "source": [
    "* Remember that the denominator $P(d)$ can be written in another way, write that out in the cell below in markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14a138",
   "metadata": {},
   "source": [
    "$$\n",
    "P(d) = your answer here\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526895b",
   "metadata": {},
   "source": [
    "Let's say we've observed the mouses choices on previous days, and have counted the number of times it choose water and the number of times it choose food. With that information we assign a prior distribution to $P(\\theta)$. Out of 868 choices it chose water 238 times, and food 630 times. We'll use this information to create a prior distribution for $\\theta$ below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3151b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_water_choices = 358\n",
    "prior_total_choices = 868\n",
    "prior_food_choices = prior_total_choices - prior_water_choices\n",
    "prior_water = beta(prior_water_choices, prior_food_choices)\n",
    "prior_water; # this is a set beta distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e50fdf",
   "metadata": {},
   "source": [
    "Let's assume a discrete grid for all the values that $\\theta$ can take on, and set some other important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e3b98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_thetas = np.linspace(0.001, 0.99, 1000)\n",
    "\n",
    "true_water_pref = 0.56 # ground truth\n",
    "\n",
    "data = bernoulli(p=true_water_pref).rvs(600) # generate some data from the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72481fc3",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "\n",
    "When you have an array of data points as we do, how do we compute $P(d | \\theta)$? The first thing to realize is that $P(d | \\theta)$ is a shortened version of: \n",
    "\n",
    "$$P(0, 1, 1, 0, 1, 1, 0, 1, 0, 1, ... | \\theta)$$\n",
    "\n",
    "additionally we make an assumption of independence and identitically distributed. This means that we are assuming each sample uses the same distributtion for it's likelihood function, and that each sample is independent of one another (obviously this lattter assumption is wrong). \n",
    "\n",
    "Now recall that if two events are independent then: $P(a, b) = P(a)P(b)$. Use this fact to both write out in markdown the from of the likelihood, and code it up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb20649",
   "metadata": {},
   "source": [
    "$$P(d | \\theta) = your answer here$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a3d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an example P( 1 | theta = 0.5): bernoulli(p=0.5).pmf(1)\n",
    "# use that to computue P(d | theta), for the moment assume a theta of 0.5\n",
    "\n",
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767be0c",
   "metadata": {},
   "source": [
    "Repeat what you've done above, but this time compute that likelihood for all values in the array `possible_thetas`, then normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40c74974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057d6c5",
   "metadata": {},
   "source": [
    "Do what you just did again, however this time take into account the prior distribution over $\\theta$. Use the function that was created for you `prior_water`, it has a probability density method associated with it, here's how you'd use it: \n",
    "\n",
    "`prior_water.pdf(theta_value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904860fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76f4f83f",
   "metadata": {},
   "source": [
    "Plot the two distributions, and observe the effect of the prior. Use the information you gather from plotting these distributions to say something about the mouses preference for water, explain what the prior does, is it a good prior in this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe45340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817145c",
   "metadata": {},
   "source": [
    "Explain yourself here: "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
